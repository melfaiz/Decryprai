{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Playing decrypto with AI"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Importing librairies"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from scipy import spatial\n",
    "from scipy import ndimage\n",
    "\n",
    "dim = 300 #Dimension of the embeddings"
   ]
  },
  {
   "source": [
    "Saving pre-trained word embeddings dict to pickle format"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings_dict = {}\n",
    "# with open(\"glove.6B.300d.txt\", 'r',encoding=\"utf-8\") as f:\n",
    "#     for line in f:\n",
    "#         values = line.split()\n",
    "#         word = values[0]\n",
    "#         vector = np.asarray(values[1:], \"float32\")\n",
    "#         embeddings_dict[word] = vector\n",
    "# with open('data_300.pickle', 'wb') as handle:\n",
    "#     pickle.dump(embeddings_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "source": [
    "Loading pre-trained word embeddings from the pickle file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_300.pickle', 'rb') as fp:\n",
    "    embeddings_dict = pickle.load(fp)"
   ]
  },
  {
   "source": [
    "Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centers(hints):\n",
    "    centers = []\n",
    "    for hints_list in hints:\n",
    "        embeddings = []\n",
    "        if hints_list == []:\n",
    "            centers.append(np.zeros(dim))\n",
    "        else :\n",
    "            for word in hints_list:\n",
    "                embeddings.append(embeddings_dict[word])\n",
    "            centers.append(np.sum(embeddings,axis=0)/len(embeddings))\n",
    "    return centers\n",
    "    \n",
    "def guess_word_1(hints,new_hint):\n",
    "    embedding = embeddings_dict[new_hint]\n",
    "    D = []\n",
    "    for word_list in hints:\n",
    "        dist = 0\n",
    "        for word in word_list :\n",
    "            dist += spatial.distance.cosine(embeddings_dict[word], embedding)\n",
    "        D.append(dist)\n",
    "    return np.argmin(D)\n",
    "\n",
    "def guess_word_2(hints_centers,new_hint):\n",
    "    embedding = embeddings_dict[new_hint]\n",
    "    D = []\n",
    "    for rep in hints_centers:\n",
    "        dist = spatial.distance.cosine(rep, embedding)\n",
    "        D.append(dist)\n",
    "    return np.argmin(D)"
   ]
  },
  {
   "source": [
    "Finding the closest group of word to the new hint "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['fruits','clothes','technology','sports']\n",
    "\n",
    "hints = [['orange'],\n",
    "         ['pants'],\n",
    "         ['phone'],\n",
    "         ['football','run']]\n",
    "\n",
    "new_hint = 'golf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "New hint :  golf\nSum of errors :  clothes\nWords centers :  sports\n"
     ]
    }
   ],
   "source": [
    "print(\"New hint : \",new_hint)\n",
    "print(\"Sum of errors : \",keys[guess_word_1(hints,new_hint)])\n",
    "print(\"Words centers : \",keys[guess_word_2(get_centers(hints),new_hint)])"
   ]
  },
  {
   "source": [
    "Generating four random words from the words list"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wordlist.txt', 'r') as file:\n",
    "    content = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['SLIP', 'RING', 'WAGON', 'JOURNEY']\n"
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "#Generate 5 random numbers between 10 and 30\n",
    "randomlist = sample(range(len(content)), 4)\n",
    "print([content[i] for i in randomlist])"
   ]
  },
  {
   "source": [
    "Finding closest words to a word with consine/euclidean distance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_words(word,n):\n",
    "    embedding = embeddings_dict[word]\n",
    "    return sorted(embeddings_dict.keys(), key=lambda item: spatial.distance.euclidean(embeddings_dict[item], embedding))[1:n+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['sport', 'sporting', 'basketball', 'baseball', 'soccer']"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "find_closest_words('sports',5)"
   ]
  }
 ]
}